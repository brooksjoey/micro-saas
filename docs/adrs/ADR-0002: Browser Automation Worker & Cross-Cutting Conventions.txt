ADR-0002: Browser Automation Worker & Cross-Cutting Conventions

# ADR-0002: Browser Automation Worker & Cross-Cutting Conventions

## Status
**Accepted** - 2024-01-16

## Context
Phase 1 introduced a FastAPI-based backend with an async PostgreSQL layer, Redis-backed job queue, structured JSON logging, and OpenTelemetry instrumentation. A generic job worker consumed jobs from a Redis list and updated a shared jobs table.

Phase 2 adds a headless browser automation worker built on Playwright and Redis Streams with at-least-once delivery semantics. The initial Phase 2 design introduced a separate configuration object, Redis key names, and partial telemetry, which risked divergence from the conventions established in Phase 1:

- Different Redis key naming and queue semantics (list + sorted set vs Redis Streams)
- Inconsistent Redis client configuration (decode_responses mismatch)
- Incomplete correlation ID propagation from HTTP request → job enqueue → worker logs/traces
- New circuit breaker implementation used only for Playwright
- Ad-hoc span names and metrics naming in the worker
- No clear feature flag keys for enabling/disabling the browser worker or specific tasks
- No OCI/Compose labels to distinguish API vs worker roles

To keep the system at Stripe/Shopify-grade maintainability and observability, we must define a single set of conventions and apply them across both phases.

## Decision

### 1. Configuration and Naming Standards

**Configuration Hierarchy:**
- `app.config.Settings` remains the source of truth for global configuration (DB, Redis, OTEL, Sentry, and default job thresholds)
- `worker.config.WorkerSettings` is limited to worker-specific tuning (stream keys, consumer group, concurrency, Playwright and circuit breaker overrides, metrics port)

**Redis Key Naming Convention:**
```

jobs:{namespace}:{type}

```

**Concrete Implementations:**
- Generic worker (existing):
  - `jobs:default:queue` (list)
  - `jobs:default:scheduled` (sorted set) 
  - `jobs:default:lock:{job_id}` (lock key)

- Browser worker (new):
  - `jobs:browser:stream`
  - `jobs:browser:group`
  - `jobs:browser:dlq` (reserved for dead-letter use)

**Canonical Redis Message Payload:**
```json
{
  "job_id": "uuid",
  "attempt": 0,
  "correlation_id": "uuid-or-upstream-id",
  "task_type": "string",
  "meta": {
    "enqueue_ts": "ISO8601",
    "user_id": "uuid",
    "source": "api"
  }
}
```

2. Correlation ID Propagation and Distributed Tracing

HTTP Layer:

· CorrelationIdMiddleware remains the single source of correlation IDs via x-request-id header
· When enqueuing jobs, API embeds correlation ID into both Redis envelope and job record

Worker Layer:

· Workers set correlation_id_var from message correlation_id when available
· Fallback to stored value in DB, then generate new UUID only as last resort

OpenTelemetry Span Naming:

· Outer span per job: jobs.process
· Inner browser span: jobs.browser.automation
· Span attributes: job.id, job.attempt, job.task_type, job.queue, job.correlation_id

3. Redis Streams Semantics

Consumer Group Strategy:

· Single consumer group: jobs:browser:group on stream key jobs:browser:stream
· Consumer names: {hostname}:{pid}:{index} for observability

Message Acknowledgment:

· Messages acknowledged (XACK) only after:
  · Job status updated in PostgreSQL
  · Browser automation completed (success or permanent failure)

Retry Strategy:

· Retries implemented by re-adding messages to stream with incremented attempt
· Retry policy uses lower of Job.max_attempts and Settings.JOB_MAX_ATTEMPTS

4. Circuit Breaker Implementation

Shared Library:

· utils.circuit_breaker.CircuitBreaker is canonical implementation
· All external dependencies (Playwright, Stripe, HTTP APIs) must use this implementation

Configuration:

```python
# Global defaults in Settings
CIRCUIT_FAILURE_THRESHOLD_DEFAULT: int = 5
CIRCUIT_RESET_TIMEOUT_SECONDS_DEFAULT: int = 60

# Worker overrides in WorkerSettings  
PLAYWRIGHT_CIRCUIT_FAILURE_THRESHOLD: int
PLAYWRIGHT_CIRCUIT_RESET_TIMEOUT_SECONDS: int
```

Circuit Open Behavior:

· Worker re-schedules job with incremented attempt
· Expose Prometheus gauge: circuit_state{target="playwright"} (0=closed, 1=half-open, 2=open)

5. Feature Flag Standards

Naming Convention:

· Prefix: FF_ for environment-controlled flags
· Browser worker flags:
  · FF_BROWSER_WORKER_ENABLED (global on/off)
  · FF_BROWSER_TASK_{TASK_NAME}_ENABLED (per task-type)

Behavior:

· If FF_BROWSER_WORKER_ENABLED=false: worker logs clear message and exits
· If task-type flag disabled: job failed with "feature_flag_disabled" reason

6. Logging and Metrics Standards

Logging:

· Single configuration: app.logging.configure_logging()
· Common log fields: correlation_id, job_id injected via context variables
· Consistent snake_case event names:
  · job_enqueued
  · job_automation_completed
  · job_automation_failed_permanently
  · job_automation_scheduled_retry
  · job_stream_message_processed

Metrics Naming:

```python
# Browser worker metrics
jobs_browser_processing_seconds (Histogram)
jobs_browser_errors_total{reason} (Counter)
jobs_browser_processed_total{status} (Counter) 
jobs_browser_pending_messages (Gauge)
circuit_state{target="playwright"} (Gauge)
```

7. Docker and Container Standards

OCI Image Labels:

```dockerfile
org.opencontainers.image.title=micro-saas-core
org.opencontainers.image.source=${GIT_REPO}
org.opencontainers.image.version=${VERSION}
org.opencontainers.image.description=Core API and workers for Micro-SaaS automation
```

Compose Service Labels:

```yaml
com.micro-saas.service.role=api|worker|browser-worker
com.micro-saas.environment=${APP_ENV}
```

Service Naming:

· Browser worker service: browser-worker
· Entrypoint: python -m worker.run

Consequences

Positive

· Unified Observability: Browser automation integrates with existing logging, correlation IDs, and trace structure
· Consistent Operations: Redis usage follows uniform naming and message schemas
· Reusable Patterns: Circuit breaker and feature flag patterns applicable to other external dependencies
· Operational Clarity: Tooling works uniformly across API, generic workers, and browser workers

Negative

· Increased Complexity: Additional schema work required (job correlation ID column)
· Redis Fragmentation: Mixed list + streams architecture requires dual operational knowledge
· Configuration Overhead: Multiple settings classes require careful dependency management

Neutral

· Backward Compatibility: Existing generic worker remains unchanged
· Progressive Enhancement: Dead-letter queue and pending message handling deferred to future iterations

Compliance Verification

This ADR ensures all Phase 2 implementation will adhere to enterprise standards:

· ✅ Zero-trust security with consistent secret management
· ✅ End-to-end observability with correlation ID propagation
· ✅ SLO-driven development with unified metrics
· ✅ Resilience engineering with shared circuit breaker
· ✅ Production-grade operations with standardized container labeling
· ✅ Comprehensive testing with consistent patterns
· ✅ Maintainability with explicit architectural boundaries

The Phase 2 implementation will follow these conventions rather than the earlier draft, ensuring Stripe/Shopify-grade production readiness.

```
